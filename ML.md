# Экзаминационные билеты

# Билет 1

## Основные термины и задачи машинного обучения.

### Основные термины
- Данные (Data): Сбор, обработка и анализ данных, которые используются для обучения моделей машинного обучения.
- Модель (Model): Математическое представление, которое описывает взаимосвязь между входными и выходными данными. Модели обучаются на основе данных.
- Обучение (Training): Процесс, в котором модель обучается на основе данных, чтобы улучшить свои прогнозы или решения.
- Тестирование (Testing): Процесс проверки производительности модели на новых данных, которые не использовались в процессе обучения.
- Оценка (Evaluation): Процесс оценки производительности модели, используя различные метрики, такие как точность, полнота, F-мера и другие.
- Оверфиттинг (Overfitting): Ситуация, когда модель слишком хорошо обучается на тренировочных данных и плохо работает на новых данных.
- Подвыборка (Underfitting): Ситуация, когда модель недообучена и не может адекватно предсказывать результаты на новых данных.
- Кросс-валидация (Cross-validation): Техника, используемая для оценки производительности модели на различных подмножествах данных.
- Гиперпараметры (Hyperparameters): Параметры модели, которые задаются до начала процесса обучения и влияют на процесс обучения.
- Обучающий набор данных (Training set): Подмножество данных, используемое для обучения модели.
- Тестовый набор данных (Test set): Подмножество данных, используемое для тестирования модели после обучения.
- Валидационный набор данных (Validation set): Подмножество данных, используемое для настройки гиперпараметров модели.

### Основные задачи

- Классификация (Classification): Задача предсказания класса объекта на основе его признаков.
- Регрессия (Regression): Задача предсказания непрерывного значения на основе признаков объекта.
- Кластеризация (Clustering): Задача группировки объектов по схожести признаков.
- Определение границ (Boundary Detection): Задача определения границ между различными классами в данных.
- Распознавание образов (Image Recognition): Задача идентификации объектов на изображениях.
- Распознавание речи (Speech Recognition): Задача преобразования аудио в текст.
- Рекомендательные системы (Recommendation Systems): Системы, предлагающие пользователям список предпочтительных товаров или услуг на основе их предыдущих выборов.
- Прогнозирование временных рядов (Time Series Forecasting): Задача предсказания будущих значений на основе исторических данных.
- Аномалия обнаружение (Anomaly Detection): Задача обнаружения необычных или аномальных данных в наборе данных.
- Оптимизация (Optimization): Задача нахождения наилучшего решения из возможных на основе заданных ограничений.

## Признаки, их виды и свойства. Переход между категориальными и численными признаками.

### Признаки 
Атрибуты или характеристики, которые используются для обучения моделей. Они могут быть категориальными или численными, и каждый тип признака имеет свои особенности.

### Виды признаков:
- Категориальные признаки: Это признаки, которые могут принимать ограниченное количество различных значений. Примеры включают пол (мужской, женский), цвет глаз (синий, зеленый, коричневый), тип автомобиля (седан, хетчбэк, универсал) и т.д.
- Численные признаки: Это признаки, которые могут принимать любое значение в некотором диапазоне. Примеры включают возраст, вес, высоту, температуру, расстояние и т.д.
### Свойства признаков:
- Непрерывность: Численные признаки обычно непрерывны, в то время как категориальные признаки могут быть дискретными.
- Ограниченность: Категориальные признаки обычно имеют ограниченное количество возможных значений, в то время как численные признаки могут принимать любое значение в определенном диапазоне.
- Скалярность: Численные признаки обычно являются скалярными, то есть они имеют одно значение на каждый момент времени или для каждого объекта. Категориальные признаки могут быть скалярными или векторными, в зависимости от того, как они кодируются.

### Переход между категориальными и численными признаками:
Переход между категориальными и численными признаками часто требуется для обработки данных в машинном обучении. Этот процесс называется кодированием признаков.

- Один-горячий кодирование (One-hot encoding): Этот метод используется для преобразования категориальных признаков в численные. Каждому уникальному значению категориального признака присваивается свой уникальный бинарный признак (0 или 1), который указывает на наличие или отсутствие этого значения.
- Линейное кодирование (Ordinal encoding): Этот метод подразумевает присвоение числовых значений категориальным признакам на основе их порядка. Этот метод подходит для признаков с порядком, но не рекомендуется для признаков без явного порядка.
- Кодирование метками (Label encoding): Этот метод присваивает каждому уникальному значению категориального признака уникальное целое число. Этот метод подходит для признаков с небольшим количеством уникальных значений, но может привести к проблемам, если модель интерпретирует эти числа как порядок.
- Кодирование с использованием деревьев решений (Decision tree encoding): Этот метод использует деревья решений для кодирования категориальных признаков в численные, учитывая структуру данных.
Переход между категориальными и численными признаками важен для подготовки данных к обучению моделей машинного обучения, поскольку многие алгоритмы требуют численные входные данные.

## Функция потерь. Оптимизация.

Функция потерь (loss function) и оптимизация являются ключевыми компонентами в процессе обучения моделей машинного обучения. Они определяют, как модель оценивает свои прогнозы и как она стремится улучшить свои прогнозы на основе обучающих данных.

### Функция потерь
Функция потерь измеряет разницу между реальными значениями и прогнозами модели. Цель обучения модели — минимизировать значение функции потерь. Функции потерь могут быть различными в зависимости от типа задачи машинного обучения:

- Классификация:
    - Кросс-энтропия (Cross-entropy): Используется для бинарной и многоклассовой классификации.
    - Логистическая потеря (Logistic loss): Используется для бинарной классификации.
- Регрессия:
    - Среднеквадратичная ошибка (Mean Squared Error, MSE): Используется для измерения среднего квадрата разности между реальными и прогнозируемыми значениями.
    - Средняя абсолютная ошибка (Mean Absolute Error, MAE): Используется для измерения среднего абсолютного разности между реальными и прогнозируемыми значениями.
- Распознавание образов:
    - Ошибка пересечения (Cross-entropy loss): Используется в сверточных нейронных сетях для классификации изображений.

### Оптимизация
Процесс настройки параметров модели для минимизации функции потерь. Для этого используются различные алгоритмы оптимизации, такие как градиентный спуск, стохастический градиентный спуск (SGD), Adam, RMSprop и другие.

- Градиентный спуск — это метод оптимизации, который итеративно обновляет параметры модели в направлении, противоположном градиенту функции потерь, с целью минимизации функции потерь.
- Стохастический градиентный спуск (SGD) — это вариация градиентного спуска, которая обновляет параметры модели после каждого примера обучающих данных, что делает процесс обучения более быстрым и эффективным, особенно на больших наборах данных.
- Adam — это алгоритм оптимизации, который адаптирует скорость обучения для каждого параметра, что позволяет более быстро сходиться к оптимальному решению.
- RMSprop — это алгоритм оптимизации, который также адаптирует скорость обучения для каждого параметра, но делает это более плавно, чем Adam.

Выбор алгоритма оптимизации зависит от конкретной задачи, типа модели и данных. Важно правильно настроить параметры оптимизации, такие как скорость обучения, чтобы обеспечить эффективное обучение модели.

## Ошибки первого и второго рода. Метрики качества: accuracy, precision, recall, F1-score.

Ошибки первого и второго рода относятся к классификационным задачам машинного обучения, где модель предсказывает принадлежность объекта к одному из двух или более классов. Эти ошибки определяют, как модель ошибается в своих прогнозах.

- Ошибки первого рода:
    - Истинно положительные (True Positives, TP): Количество объектов, которые модель правильно классифицировала как положительные.
    - Истинно отрицательные (True Negatives, TN): Количество объектов, которые модель правильно классифицировала как отрицательные.
- Ошибки второго рода:
    - Ложно положительные (False Positives, FP): Количество объектов, которые модель неправильно классифицировала как положительные.
    - Ложно отрицательные (False Negatives, FN): Количество объектов, которые модель неправильно классифицировала как отрицательные.

### Метрики качества:
- Точность (Accuracy): Отношение количества правильно классифицированных объектов к общему количеству объектов. 
```Accuracy = (TP + TN) / (TP + TN + FP + FN)```
- Точность (Precision): Отношение количества истинно положительных объектов к сумме истинно положительных и ложно положительных объектов. ```Precision = TP / (TP + FP)```
- Полнота (Recall): Отношение количества истинно положительных объектов к сумме истинно положительных и ложно отрицательных объектов. ```Recall = TP / (TP + FN)```
- F1-оценка (F1 Score): Гармоническое среднее точности и полноты. ```F1-Score = 2 * (Precision * Recall) / (Precision + Recall)```

Эти метрики качества позволяют оценить производительность модели классификации. Выбор метрики зависит от конкретной задачи и от того, какие ошибки более критичны для решения. Например, в задачах, где ложно положительные ошибки могут быть более серьезными, чем ложно отрицательные, может быть предпочтительнее использовать точность или F1-оценку.

## Случайный поиск. Перебор по сетке.

Случайный поиск и перебор по сетке — это два метода оптимизации гиперпараметров в машинном обучении, которые используются для настройки моделей. Они помогают найти оптимальные значения гиперпараметров, которые минимизируют функцию потерь или максимизируют метрику качества.

### Случайный поиск (Random Search)
Метод, при котором гиперпараметры выбираются случайным образом из заданного диапазона или набора значений. Этот метод не гарантирует, что будет найдено глобальное оптимальное решение, но он эффективен для исследования пространства гиперпараметров и может быть быстрее, чем более тщательные методы, такие как перебор по сетке, особенно когда пространство гиперпараметров очень большое.

Пример реализации случайного поиска с использованием библиотеки scikit-learn в Python:
```
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Определение гиперпараметров для поиска
param_dist = {
    'n_estimators': np.arange(10, 200, 10),
    'max_depth': np.arange(1, 20, 1),
    'min_samples_split': np.arange(2, 20, 2),
    'min_samples_leaf': np.arange(1, 20, 2),
}

# Создание классификатора
clf = RandomForestClassifier()

# Создание объекта RandomizedSearchCV
random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=100, cv=5, verbose=2, random_state=42)

# Обучение модели
random_search.fit(X_train, y_train)

# Вывод лучших параметров
print("Лучшие параметры: ", random_search.best_params_)

```
### Перебор по сетке (Grid Search)
Метод, при котором гиперпараметры перебираются по заранее определенной сетке значений. Этот метод более тщателен, чем случайный поиск, и может найти более оптимальное решение, но он также требует больше времени и ресурсов, особенно когда пространство гиперпараметров большое.

Пример реализации перебора по сетке с использованием scikit-learn:
```
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Определение гиперпараметров для поиска
param_grid = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [1, 5, 10, 20],
    'min_samples_split': [2, 5, 10, 20],
    'min_samples_leaf': [1, 5, 10, 20],
}

# Создание классификатора
clf = RandomForestClassifier()

# Создание объекта GridSearchCV
grid_search = GridSearchCV(clf, param_grid, cv=5, verbose=2)

# Обучение модели
grid_search.fit(X_train, y_train)

# Вывод лучших параметров
print("Лучшие параметры: ", grid_search.best_params_)
```

Выбор между случайным поиском и перебором по сетке зависит от конкретной задачи, доступных ресурсов и требований к времени.

## Проблемы работы с данными высокой размерности.

Работа с данными высокой размерности (high-dimensional data) представляет собой ряд проблем, которые могут существенно влиять на эффективность и результаты машинного обучения. Вот некоторые из наиболее распространенных проблем:

- Куриозный эффект (Curse of Dimensionality)
Куриозный эффект описывает проблему, когда пространство данных становится настолько большим, что оно становится "разреженным" и "искаженным". Это приводит к тому, что данные становятся менее различимыми и труднее для моделей машинного обучения обрабатывать.

- Проблема разреженности (Sparsity Problem)
В данных высокой размерности многие признаки могут быть нерелевантными или иметь очень низкую корреляцию с целевой переменной, что приводит к разреженности данных. Это может затруднить обучение моделей, особенно если модель зависит от наличия информации в каждом признаке.

- Проблема выбора признаков (Feature Selection Problem)
Выбор подмножества признаков из большого набора может быть сложной задачей, поскольку нет универсального способа определить, какие признаки наиболее важны. Это может привести к тому, что модель будет переобучена на выбранных признаках и плохо справится с новыми данными.

- Проблема переобучения (Overfitting)
Модели машинного обучения могут легко переобучиться на данных высокой размерности, особенно если они имеют большое количество признаков, которые не имеют значительного влияния на целевую переменную. Это может привести к тому, что модель будет плохо справляться с новыми данными.

- Проблема вычислительной эффективности
Алгоритмы машинного обучения могут стать неэффективными при работе с данными высокой размерности из-за увеличения вычислительных затрат. Это может включать в себя увеличение времени обучения, увеличение потребления памяти и увеличение сложности алгоритмов.

- Проблема интерпретируемости
Модели, обученные на данных высокой размерности, могут быть менее интерпретируемыми. Это означает, что может быть труднее понять, какие признаки влияют на прогнозы модели, что важно для многих приложений.

### Решения
Для работы с данными высокой размерности можно использовать различные техники, такие как:

- Уменьшение размерности (Dimensionality Reduction): Техники, такие как главные компоненты анализа (PCA), t-SNE, UMAP, позволяют уменьшить размерность данных, сохраняя при этом важную информацию.
- Регуляризация (Regularization): Добавление регуляризации в модели может помочь предотвратить переобучение и сделать модели более устойчивыми к шуму в данных.
- Выбор признаков (Feature Selection): Использование методов выбора признаков может помочь определить наиболее важные признаки и уменьшить размерность данных.
- Использование ансамблевых методов (Ensemble Methods): Ансамблевые методы, такие как случайный лес или градиентный бустинг, могут быть более устойчивыми к шуму в данных и могут лучше справляться с данными высокой размерности.

# Билет 2

## Производная, частные производные, градиент. Методы оценки градиента.

### Производная, частные производные, градиент

#### Производная 
Мера скорости изменения функции в точке. Если функция (f(x)) изменяется в точке (x), то производная функции в этой точке равна скорости изменения функции.

#### Частные производные 
Производные функции по отдельным переменным. Если функция (f(x, y)) имеет две переменные, то частные производные по (x) и (y) определяют, как функция изменяется при изменении (x) и (y) соответственно.

#### Градиент 
Вектор, состоящий из частных производных функции по каждой из переменных. Градиент указывает направление наибольшего возрастания функции.

### Методы оценки градиента
- Аналитический метод: Если производная функции потерь можно выразить аналитически, то можно напрямую вычислить градиент. Это самый простой и быстрый метод, но он не всегда применим, особенно для сложных функций.
- Численный метод: Если аналитический метод неприменим, можно использовать численные методы для оценки градиента. Наиболее распространенные численные методы включают:
- Метод конечных разностей: Оценка производной с использованием разностей между значениями функции в близких точках.
- Метод символьных вычислений: Использование символьных вычислений для автоматического вычисления производных.
- Автоматическое дифференцирование: Многие библиотеки машинного обучения, такие как TensorFlow и PyTorch, используют автоматическое дифференцирование для вычисления градиентов. Это позволяет автоматически вычислять градиенты для сложных выражений и функций, что делает процесс обучения более эффективным и удобным.

Пример вычисления градиента с использованием численного метода
Допустим, у нас есть функция потерь $$(L(x, y) = (x - 2)^2 + (y - 3)^2).$$ Мы хотим вычислить градиент этой функции в точке $((x, y) = (1, 1))$.

Используя метод конечных разностей для частных производных:

Частная производная по $$(x): (\frac{\partial L}{\partial x} \approx \frac{L(x + \epsilon, y) - L(x - \epsilon, y)}{2\epsilon}),$$ где $(\epsilon)$ — небольшое число.
Частная производная по $$(y): (\frac{\partial L}{\partial y} \approx \frac{L(x, y + \epsilon) - L(x, y - \epsilon)}{2\epsilon}).$$
Подставив значения $((x, y) = (1, 1))$ и вычислив, получим градиент функции в этой точке.

## Градиентный спуск, проблема выбора шага.

### Градиентный спуск

Метод оптимизации, используемый для нахождения минимума функции потерь. Он работает путем итеративного обновления параметров модели в направлении, противоположном градиенту функции потерь, с целью минимизации функции потерь.

### Проблема выбора шага.

Одной из ключевых проблем в градиентном спуске является выбор подходящего размера шага (или скорости обучения) для каждой итерации. Неправильный выбор шага может привести к тому, что алгоритм не сможет сходиться к оптимальному решению или будет сходиться слишком медленно.

#### Проблемы:
- Слишком большой шаг: Если шаг слишком большой, алгоритм может "пропустить" минимум функции потерь и продолжить движение в неправильном направлении.
- Слишком маленький шаг: Если шаг слишком маленький, алгоритм может сходиться очень медленно, поскольку каждое обновление параметров будет незначительным.
- Нестабильность: Выбор шага может быть нестабильным, особенно в начале обучения, когда градиент может быть большим. Это может привести к тому, что алгоритм будет "перепрыгивать" минимум функции потерь.

#### Решения:
- Адаптивный шаг: Использование методов, таких как метод Адам (Adaptive Moment Estimation), которые адаптируют размер шага в зависимости от предыдущих градиентов и обновлений параметров.
- Применение градиентного спуска с моментом: Этот метод добавляет момент к обновлению параметров, что помогает ускорить сходимость и сгладить движение в направлении минимума.
- Применение градиентного спуска с адаптивным шагом: Методы, такие как RMSprop или Adam, адаптируют размер шага для каждого параметра, учитывая историю градиентов и обновлений параметров.
- Использование линейного поиска шага: В некоторых случаях можно использовать линейный поиск шага для определения оптимального размера шага, но это может быть ресурсоемким и не всегда применимым.

## Стохастический градиентный спуск (Stochastic Gradient Descent, SGD)
Вариация градиентного спуска, которая обновляет параметры модели после каждого примера обучающих данных, а не после прохождения через весь набор данных. Это делает процесс обучения более быстрым и эффективным, особенно на больших наборах данных.

### Принцип работы
В классическом градиентном спуске, градиент функции потерь вычисляется для всего набора обучающих данных, и затем параметры модели обновляются на основе этого градиента. В стохастическом градиентном спуске, градиент вычисляется для каждого примера обучающих данных последовательно, и параметры модели обновляются после каждого примера.

### Преимущества
- Быстрота обучения: Поскольку обновления параметров происходят после каждого примера, SGD может сходиться к минимуму функции потерь быстрее, чем классический градиентный спуск.
- Обработка больших наборов данных: SGD может эффективно обрабатывать очень большие наборы данных, поскольку он не требует загрузки всего набора данных в память.
- Регуляризация: SGD может служить формой регуляризации, поскольку частое обновление параметров может привести к более устойчивым и обобщающим моделям.

### Недостатки
- Нестабильность: Из-за случайного выбора примеров для обновления параметров, SGD может быть менее стабильным в сходимости по сравнению с классическим градиентным спуском.
- Требует больше итераций для сходимости: Поскольку обновления параметров происходят после каждого примера, SGD может требовать больше итераций для достижения сходимости по сравнению с классическим градиентным спуском.

Пример использования SGD в Python с использованием библиотеки scikit-learn:
```
from sklearn.linear_model import SGDRegressor
from sklearn.datasets import make_regression

# Генерация набора данных
X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)

# Создание и обучение модели SGD
sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)
sgd_reg.fit(X, y)

# Предсказание на новых данных
X_new = [[0, 0], [1, 1]]
y_pred = sgd_reg.predict(X_new)
print(y_pred)
```

В этом примере используется SGDRegressor для регрессии, но scikit-learn также предоставляет аналогичные классы для классификации (SGDClassifier) и других задач.

## Использование момента. Метод Нестерова.

### Использование момента
Техника, которая использует информацию о предыдущих обновлениях параметров для ускорения сходимости алгоритма. Она особенно полезна в методах градиентного спуска, где каждое обновление параметров зависит от текущего градиента. Использование момента позволяет алгоритму "ускользать" от локальных минимумов и сходиться к глобальному минимуму быстрее.

### Метод Нестерова
Также известный как Nesterov Accelerated Gradient (NAG), — это вариация метода градиентного спуска с моментом, которая использует предсказание следующего шага для ускорения сходимости. Этот метод был предложен Юрием Нестеровым в 1983 году.

#### Принцип работы
В классическом методе градиентного спуска с моментом, обновление параметров происходит следующим образом:

$$ v_{t+1} = \mu v_t - \eta \nabla L(\theta_t) $$

$$ \theta_{t+1} = \theta_t + v_{t+1} $$

где $(v_t)$— это скорость, $(\mu)$ — коэффициент момента, $(\eta)$ — скорость обучения, $(\theta_t)$ — текущие параметры, и $(\nabla L(\theta_t))$ — градиент функции потерь в точке $(\theta_t)$.

Метод Нестерова изменяет этот процесс, предсказывая следующий шаг перед обновлением параметров:

$$ v_{t+1} = \mu v_t - \eta \nabla L(\theta_t - \mu v_t) $$

$$\theta_{t+1} = \theta_t + v_{t+1} $$

Этот предсказательный шаг позволяет алгоритму "ускользать" от локальных минимумов и сходиться к глобальному минимуму быстрее.

#### Преимущества
- Быстрая сходимость: Метод Нестерова обычно сходится быстрее, чем классический метод градиентного спуска с моментом, особенно на сложных функциях потерь.
- Устойчивость: Он также может быть более устойчивым к выбросам в данных и к нестабильным градиентам.

Пример использования метода Нестерова в Python
```
from sklearn.linear_model import SGDRegressor
from sklearn.datasets import make_regression

# Генерация набора данных
X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)

# Создание и обучение модели SGD с моментом Нестерова
sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1, momentum=0.9)
sgd_reg.fit(X, y)

# Предсказание на новых данных
X_new = [[0, 0], [1, 1]]
y_pred = sgd_reg.predict(X_new)
print(y_pred)
```
В этом примере используется SGDRegressor с параметром momentum=0.9, что соответствует использованию метода Нестерова.

## Метод отжига

Метод оптимизации, которая используется для поиска минимума функции потерь в задачах машинного обучения. Он основан на идее постепенного уменьшения скорости обучения (или "температуры") в процессе обучения, что позволяет алгоритму "отжигаться" в глубину потенциального пространства функции потерь, избегая застревания в локальных минимумах.

### Принцип работы
Метод отжига начинает с высокой скорости обучения, которая постепенно уменьшается с каждой итерацией. Это позволяет алгоритму "отжигаться" в глубину потенциального пространства функции потерь, избегая застревания в локальных минимумах. В конце процесса обучения скорость обучения становится очень маленькой, что позволяет алгоритму сходиться к глобальному минимуму.

### Применение
Метод отжига широко используется в различных областях машинного обучения, включая оптимизацию гиперпараметров, обучение глубоких нейронных сетей и другие задачи, где требуется нахождение минимума функции потерь.

Пример использования метода отжига в Python
```
import numpy as np

def annealing_optimization(f, x0, T=1.0, alpha=0.9, max_iter=1000):
    """
    f: функция потерь
    x0: начальное приближение
    T: начальная температура
    alpha: коэффициент уменьшения температуры
    max_iter: максимальное количество итераций
    """
    x = x0
    for t in range(max_iter):
        T *= alpha
        dx = np.random.normal(size=x.shape)
        x_new = x + dx
        delta = f(x_new) - f(x)
        if delta < 0 or np.random.rand() < np.exp(-delta / T):
            x = x_new
    return x

# Пример функции потерь
def loss_function(x):
    return np.sum(x**2)

# Начальное приближение
x0 = np.array([1.0, 1.0])

# Оптимизация
optimal_x = annealing_optimization(loss_function, x0)
print("Оптимальное приближение:", optimal_x)
```
В этом примере функция annealing_optimization реализует метод отжига для оптимизации функции потерь loss_function. Начальное приближение задается вектором x0, а параметры метода отжига (T, alpha, max_iter) задаются в соответствии с требованиями задачи.

## Adagrad, Adadelta.

### Adagrad 
Алгоритм оптимизации, который адаптирует скорость обучения для каждого параметра модели индивидуально. Это достигается путем обновления градиентов с учетом их предыдущих значений, что позволяет алгоритму "ускользать" от локальных минимумов и сходиться к глобальному минимуму.

#### Принцип работы
Adagrad использует следующую формулу для обновления параметров:

$$ [ G_t = G_{t-1} + g_t^2 ] $$

$$ [ \theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{G_t + \epsilon}} \cdot g_t ] $$

где:

$(G_t)$ — сумма квадратов градиентов до текущего шага, \
$(g_t)$ — градиент функции потерь в текущем шаге,\
$(\eta)$ — скорость обучения,\
$(\epsilon)$ — маленькое число для стабилизации деления на ноль,\
$(\theta_t)$ — параметры модели после обновления.

#### Преимущества
- Адаптивное обучение: Adagrad адаптирует скорость обучения для каждого параметра, что может ускорить сходимость и улучшить качество модели.
- Устойчивость к выбросам: Благодаря адаптивному обучению, Adagrad может быть более устойчивым к выбросам в данных.

#### Недостатки
- Затухание скорости обучения: С течением времени скорость обучения может затухать, что может замедлить сходимость.
- Требует больше памяти: Adagrad требует хранения суммы квадратов градиентов для каждого параметра, что может быть неэффективно для моделей с большим количеством параметров.

### Adadelta
Вариация Adagrad, которая пытается решить проблему затухания скорости обучения, используя экспоненциальное скользящее среднее для градиентов и их квадратов.

#### Принцип работы
Adadelta использует следующие формулы для обновления параметров:

$$ [ E[g^2]t = \gamma E[g^2]{t-1} + (1 - \gamma) g_t^2 ] $$

$$ [ E[g]t = \gamma E[g]{t-1} + (1 - \gamma) g_t ] $$

$$[ \Delta \theta_t = -\frac{\sqrt{E[\Delta \theta^2]_{t-1} + \epsilon}}{\sqrt{E[g^2]_t + \epsilon}} \cdot E[g]_t ]$$

$$[ \theta_t = \theta_{t-1} + \Delta \theta_t ]$$

где:

$(E[g^2]_t)$ и $(E[g]_t)$ — экспоненциальные скользящие средние квадратов градиентов и градиентов соответственно,
$(\gamma)$ — коэффициент забывания (обычно 0.9),
$(\epsilon)$ — маленькое число для стабилизации деления на ноль,
$(\Delta \theta_t)$ — изменение параметров,
$(\theta_t)$ — параметры модели после обновления.

#### Преимущества
- Адаптивное обучение: Как и Adagrad, Adadelta адаптирует скорость обучения для каждого параметра.
- Устойчивость к затуханию скорости обучения: Adadelta использует экспоненциальное скользящее среднее для градиентов и их квадратов, что помогает предотвратить затухание скорости обучения.

#### Недостатки
- Требует больше памяти: Adadelta также требует хранения экспоненциальных скользящих средних для каждого параметра, что может быть неэффективно для моделей с большим количеством параметров.

## RMSProp, Adam.
## По выбору студента: один из: AMSGrad, AdamW, YellowFin, AggMo, Quasi-Hyperbolic Momentum, Demon.*

# Билет 3

## Постановка задачи линейной регрессии. Вероятностная интерпретация.
## Метод наименьших квадратов. Алгебраическое и оптимизационное решения.
## Ковариация, корреляция.
## Коэффициент деретминации (критерий R2).
## Анализ остатков. Гомоскедастичность. Квартет Анскомба.
## Решение для неквадратных и плохо обусловненных матриц.
## Регуляризация LASSO, Ridge, Elastic.
## По выбору студента, одно из: Обобщённые аддитивные модели (generalized additive models)*; Partial Least Squares*.
