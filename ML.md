# Экзаминационные билеты

## Основные термины и задачи машинного обучения.

### Основные термины
- Данные (Data): Сбор, обработка и анализ данных, которые используются для обучения моделей машинного обучения.
- Модель (Model): Математическое представление, которое описывает взаимосвязь между входными и выходными данными. Модели обучаются на основе данных.
- Обучение (Training): Процесс, в котором модель обучается на основе данных, чтобы улучшить свои прогнозы или решения.
- Тестирование (Testing): Процесс проверки производительности модели на новых данных, которые не использовались в процессе обучения.
- Оценка (Evaluation): Процесс оценки производительности модели, используя различные метрики, такие как точность, полнота, F-мера и другие.
- Оверфиттинг (Overfitting): Ситуация, когда модель слишком хорошо обучается на тренировочных данных и плохо работает на новых данных.
- Подвыборка (Underfitting): Ситуация, когда модель недообучена и не может адекватно предсказывать результаты на новых данных.
- Кросс-валидация (Cross-validation): Техника, используемая для оценки производительности модели на различных подмножествах данных.
- Гиперпараметры (Hyperparameters): Параметры модели, которые задаются до начала процесса обучения и влияют на процесс обучения.
- Обучающий набор данных (Training set): Подмножество данных, используемое для обучения модели.
- Тестовый набор данных (Test set): Подмножество данных, используемое для тестирования модели после обучения.
- Валидационный набор данных (Validation set): Подмножество данных, используемое для настройки гиперпараметров модели.

### Основные задачи

- Классификация (Classification): Задача предсказания класса объекта на основе его признаков.
- Регрессия (Regression): Задача предсказания непрерывного значения на основе признаков объекта.
- Кластеризация (Clustering): Задача группировки объектов по схожести признаков.
- Определение границ (Boundary Detection): Задача определения границ между различными классами в данных.
- Распознавание образов (Image Recognition): Задача идентификации объектов на изображениях.
- Распознавание речи (Speech Recognition): Задача преобразования аудио в текст.
- Рекомендательные системы (Recommendation Systems): Системы, предлагающие пользователям список предпочтительных товаров или услуг на основе их предыдущих выборов.
- Прогнозирование временных рядов (Time Series Forecasting): Задача предсказания будущих значений на основе исторических данных.
- Аномалия обнаружение (Anomaly Detection): Задача обнаружения необычных или аномальных данных в наборе данных.
- Оптимизация (Optimization): Задача нахождения наилучшего решения из возможных на основе заданных ограничений.

## Признаки, их виды и свойства. Переход между категориальными и численными признаками.

### Признаки 
Атрибуты или характеристики, которые используются для обучения моделей. Они могут быть категориальными или численными, и каждый тип признака имеет свои особенности.

### Виды признаков:
- Категориальные признаки: Это признаки, которые могут принимать ограниченное количество различных значений. Примеры включают пол (мужской, женский), цвет глаз (синий, зеленый, коричневый), тип автомобиля (седан, хетчбэк, универсал) и т.д.
- Численные признаки: Это признаки, которые могут принимать любое значение в некотором диапазоне. Примеры включают возраст, вес, высоту, температуру, расстояние и т.д.
### Свойства признаков:
- Непрерывность: Численные признаки обычно непрерывны, в то время как категориальные признаки могут быть дискретными.
- Ограниченность: Категориальные признаки обычно имеют ограниченное количество возможных значений, в то время как численные признаки могут принимать любое значение в определенном диапазоне.
- Скалярность: Численные признаки обычно являются скалярными, то есть они имеют одно значение на каждый момент времени или для каждого объекта. Категориальные признаки могут быть скалярными или векторными, в зависимости от того, как они кодируются.

### Переход между категориальными и численными признаками:
Переход между категориальными и численными признаками часто требуется для обработки данных в машинном обучении. Этот процесс называется кодированием признаков.

- Один-горячий кодирование (One-hot encoding): Этот метод используется для преобразования категориальных признаков в численные. Каждому уникальному значению категориального признака присваивается свой уникальный бинарный признак (0 или 1), который указывает на наличие или отсутствие этого значения.
- Линейное кодирование (Ordinal encoding): Этот метод подразумевает присвоение числовых значений категориальным признакам на основе их порядка. Этот метод подходит для признаков с порядком, но не рекомендуется для признаков без явного порядка.
- Кодирование метками (Label encoding): Этот метод присваивает каждому уникальному значению категориального признака уникальное целое число. Этот метод подходит для признаков с небольшим количеством уникальных значений, но может привести к проблемам, если модель интерпретирует эти числа как порядок.
- Кодирование с использованием деревьев решений (Decision tree encoding): Этот метод использует деревья решений для кодирования категориальных признаков в численные, учитывая структуру данных.
Переход между категориальными и численными признаками важен для подготовки данных к обучению моделей машинного обучения, поскольку многие алгоритмы требуют численные входные данные.

## Функция потерь. Оптимизация.

Функция потерь (loss function) и оптимизация являются ключевыми компонентами в процессе обучения моделей машинного обучения. Они определяют, как модель оценивает свои прогнозы и как она стремится улучшить свои прогнозы на основе обучающих данных.

### Функция потерь
Функция потерь измеряет разницу между реальными значениями и прогнозами модели. Цель обучения модели — минимизировать значение функции потерь. Функции потерь могут быть различными в зависимости от типа задачи машинного обучения:

- Классификация:
    - Кросс-энтропия (Cross-entropy): Используется для бинарной и многоклассовой классификации.
    - Логистическая потеря (Logistic loss): Используется для бинарной классификации.
- Регрессия:
    - Среднеквадратичная ошибка (Mean Squared Error, MSE): Используется для измерения среднего квадрата разности между реальными и прогнозируемыми значениями.
    - Средняя абсолютная ошибка (Mean Absolute Error, MAE): Используется для измерения среднего абсолютного разности между реальными и прогнозируемыми значениями.
- Распознавание образов:
    - Ошибка пересечения (Cross-entropy loss): Используется в сверточных нейронных сетях для классификации изображений.

### Оптимизация
Процесс настройки параметров модели для минимизации функции потерь. Для этого используются различные алгоритмы оптимизации, такие как градиентный спуск, стохастический градиентный спуск (SGD), Adam, RMSprop и другие.

- Градиентный спуск — это метод оптимизации, который итеративно обновляет параметры модели в направлении, противоположном градиенту функции потерь, с целью минимизации функции потерь.
- Стохастический градиентный спуск (SGD) — это вариация градиентного спуска, которая обновляет параметры модели после каждого примера обучающих данных, что делает процесс обучения более быстрым и эффективным, особенно на больших наборах данных.
- Adam — это алгоритм оптимизации, который адаптирует скорость обучения для каждого параметра, что позволяет более быстро сходиться к оптимальному решению.
- RMSprop — это алгоритм оптимизации, который также адаптирует скорость обучения для каждого параметра, но делает это более плавно, чем Adam.

Выбор алгоритма оптимизации зависит от конкретной задачи, типа модели и данных. Важно правильно настроить параметры оптимизации, такие как скорость обучения, чтобы обеспечить эффективное обучение модели.

## Ошибки первого и второго рода. Метрики качества: accuracy, precision, recall, F1-score.

Ошибки первого и второго рода относятся к классификационным задачам машинного обучения, где модель предсказывает принадлежность объекта к одному из двух или более классов. Эти ошибки определяют, как модель ошибается в своих прогнозах.

- Ошибки первого рода:
    - Истинно положительные (True Positives, TP): Количество объектов, которые модель правильно классифицировала как положительные.
    - Истинно отрицательные (True Negatives, TN): Количество объектов, которые модель правильно классифицировала как отрицательные.
- Ошибки второго рода:
    - Ложно положительные (False Positives, FP): Количество объектов, которые модель неправильно классифицировала как положительные.
    - Ложно отрицательные (False Negatives, FN): Количество объектов, которые модель неправильно классифицировала как отрицательные.

### Метрики качества:
- Точность (Accuracy): Отношение количества правильно классифицированных объектов к общему количеству объектов. [ \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}} ]
- Точность (Precision): Отношение количества истинно положительных объектов к сумме истинно положительных и ложно положительных объектов. [ \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} ]
- Полнота (Recall): Отношение количества истинно положительных объектов к сумме истинно положительных и ложно отрицательных объектов. [ \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} ]
- F1-оценка (F1 Score): Гармоническое среднее точности и полноты. [ \text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} ]

Эти метрики качества позволяют оценить производительность модели классификации. Выбор метрики зависит от конкретной задачи и от того, какие ошибки более критичны для решения. Например, в задачах, где ложно положительные ошибки могут быть более серьезными, чем ложно отрицательные, может быть предпочтительнее использовать точность или F1-оценку.

## Случайный поиск. Перебор по сетке.

Случайный поиск и перебор по сетке — это два метода оптимизации гиперпараметров в машинном обучении, которые используются для настройки моделей. Они помогают найти оптимальные значения гиперпараметров, которые минимизируют функцию потерь или максимизируют метрику качества.

### Случайный поиск (Random Search)
Метод, при котором гиперпараметры выбираются случайным образом из заданного диапазона или набора значений. Этот метод не гарантирует, что будет найдено глобальное оптимальное решение, но он эффективен для исследования пространства гиперпараметров и может быть быстрее, чем более тщательные методы, такие как перебор по сетке, особенно когда пространство гиперпараметров очень большое.

Пример реализации случайного поиска с использованием библиотеки scikit-learn в Python:
```
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Определение гиперпараметров для поиска
param_dist = {
    'n_estimators': np.arange(10, 200, 10),
    'max_depth': np.arange(1, 20, 1),
    'min_samples_split': np.arange(2, 20, 2),
    'min_samples_leaf': np.arange(1, 20, 2),
}

# Создание классификатора
clf = RandomForestClassifier()

# Создание объекта RandomizedSearchCV
random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=100, cv=5, verbose=2, random_state=42)

# Обучение модели
random_search.fit(X_train, y_train)

# Вывод лучших параметров
print("Лучшие параметры: ", random_search.best_params_)

```
### Перебор по сетке (Grid Search)
Метод, при котором гиперпараметры перебираются по заранее определенной сетке значений. Этот метод более тщателен, чем случайный поиск, и может найти более оптимальное решение, но он также требует больше времени и ресурсов, особенно когда пространство гиперпараметров большое.

Пример реализации перебора по сетке с использованием scikit-learn:
```
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Определение гиперпараметров для поиска
param_grid = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [1, 5, 10, 20],
    'min_samples_split': [2, 5, 10, 20],
    'min_samples_leaf': [1, 5, 10, 20],
}

# Создание классификатора
clf = RandomForestClassifier()

# Создание объекта GridSearchCV
grid_search = GridSearchCV(clf, param_grid, cv=5, verbose=2)

# Обучение модели
grid_search.fit(X_train, y_train)

# Вывод лучших параметров
print("Лучшие параметры: ", grid_search.best_params_)
```

Выбор между случайным поиском и перебором по сетке зависит от конкретной задачи, доступных ресурсов и требований к времени.

## Проблемы работы с данными высокой размерности.

Работа с данными высокой размерности (high-dimensional data) представляет собой ряд проблем, которые могут существенно влиять на эффективность и результаты машинного обучения. Вот некоторые из наиболее распространенных проблем:

- Куриозный эффект (Curse of Dimensionality)
Куриозный эффект описывает проблему, когда пространство данных становится настолько большим, что оно становится "разреженным" и "искаженным". Это приводит к тому, что данные становятся менее различимыми и труднее для моделей машинного обучения обрабатывать.

- Проблема разреженности (Sparsity Problem)
В данных высокой размерности многие признаки могут быть нерелевантными или иметь очень низкую корреляцию с целевой переменной, что приводит к разреженности данных. Это может затруднить обучение моделей, особенно если модель зависит от наличия информации в каждом признаке.

- Проблема выбора признаков (Feature Selection Problem)
Выбор подмножества признаков из большого набора может быть сложной задачей, поскольку нет универсального способа определить, какие признаки наиболее важны. Это может привести к тому, что модель будет переобучена на выбранных признаках и плохо справится с новыми данными.

- Проблема переобучения (Overfitting)
Модели машинного обучения могут легко переобучиться на данных высокой размерности, особенно если они имеют большое количество признаков, которые не имеют значительного влияния на целевую переменную. Это может привести к тому, что модель будет плохо справляться с новыми данными.

- Проблема вычислительной эффективности
Алгоритмы машинного обучения могут стать неэффективными при работе с данными высокой размерности из-за увеличения вычислительных затрат. Это может включать в себя увеличение времени обучения, увеличение потребления памяти и увеличение сложности алгоритмов.

- Проблема интерпретируемости
Модели, обученные на данных высокой размерности, могут быть менее интерпретируемыми. Это означает, что может быть труднее понять, какие признаки влияют на прогнозы модели, что важно для многих приложений.

### Решения
Для работы с данными высокой размерности можно использовать различные техники, такие как:

- Уменьшение размерности (Dimensionality Reduction): Техники, такие как главные компоненты анализа (PCA), t-SNE, UMAP, позволяют уменьшить размерность данных, сохраняя при этом важную информацию.
- Регуляризация (Regularization): Добавление регуляризации в модели может помочь предотвратить переобучение и сделать модели более устойчивыми к шуму в данных.
- Выбор признаков (Feature Selection): Использование методов выбора признаков может помочь определить наиболее важные признаки и уменьшить размерность данных.
- Использование ансамблевых методов (Ensemble Methods): Ансамблевые методы, такие как случайный лес или градиентный бустинг, могут быть более устойчивыми к шуму в данных и могут лучше справляться с данными высокой размерности.


